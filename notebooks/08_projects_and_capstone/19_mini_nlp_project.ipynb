{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6cf2a29",
   "metadata": {},
   "source": [
    "# File Location: notebooks/08_projects_and_capstone/19_mini_nlp_project.ipynb\n",
    "\n",
    "# Mini NLP Project: Character-Level Language Model vs Sentiment Analysis\n",
    "\n",
    "This notebook implements a comprehensive NLP project comparing character-level language model and sentiment analysis tasks, demonstrating different approaches to text processing and generation.\n",
    "\n",
    "## Learning Objectives\n",
    "- Build character-level language models for text generation\n",
    "- Implement sentiment analysis with modern NLP techniques\n",
    "- Compare generative vs discriminative NLP models\n",
    "- Handle text preprocessing and tokenization strategies\n",
    "- Evaluate model performance on different NLP tasks\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates a comprehensive comparison between two fundamental NLP tasks: **character-level language modeling** and **sentiment analysis**. These represent two distinct paradigms in natural language processing - generative modeling and discriminative classification.\n",
    "\n",
    "**Project Overview:**\n",
    "- **Character-Level Language Model**: A generative model that learns to predict the next character in a sequence, enabling text generation\n",
    "- **Sentiment Analysis Model**: A discriminative model that classifies text into positive or negative sentiment categories\n",
    "- **Comparative Analysis**: Direct comparison of generative vs discriminative approaches on the same character-level vocabulary\n",
    "\n",
    "**Why This Comparison Matters:**\n",
    "- **Different Learning Objectives**: Generation vs classification showcase different aspects of language understanding\n",
    "- **Architecture Variations**: How the same base architecture (LSTM) adapts to different tasks\n",
    "- **Evaluation Metrics**: Perplexity vs accuracy represent different notions of model quality\n",
    "- **Practical Applications**: Understanding when to use generative vs discriminative models\n",
    "\n",
    "**Technical Highlights:**\n",
    "- Character-level tokenization for robust handling of out-of-vocabulary words\n",
    "- Bidirectional LSTM for sentiment analysis to capture full context\n",
    "- Temperature-controlled text generation for creativity vs coherence trade-offs\n",
    "- Comprehensive evaluation including qualitative analysis of model outputs\n",
    "\n",
    "This project provides hands-on experience with both major categories of NLP models while using a consistent preprocessing and evaluation framework.\n",
    "\n",
    "```python\n",
    "# Initial setup and imports are already provided above\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import random\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Lightning version: {pl.__version__}\")\n",
    "```\n",
    "\n",
    "## 1. Text Datasets and Preprocessing\n",
    "\n",
    "```python\n",
    "class TextDataProcessor:\n",
    "    \"\"\"Text data processing utilities for NLP tasks\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vocab = {}\n",
    "        self.idx_to_char = {}\n",
    "        self.char_to_idx = {}\n",
    "        self.vocab_size = 0\n",
    "        \n",
    "    def build_character_vocab(self, texts):\n",
    "        \"\"\"Build character-level vocabulary\"\"\"\n",
    "        all_chars = set()\n",
    "        for text in texts:\n",
    "            all_chars.update(text.lower())\n",
    "        \n",
    "        # Sort for consistency\n",
    "        chars = sorted(list(all_chars))\n",
    "        \n",
    "        # Add special tokens\n",
    "        special_tokens = ['<PAD>', '<UNK>', '<SOS>', '<EOS>']\n",
    "        self.vocab = {char: idx + len(special_tokens) for idx, char in enumerate(chars)}\n",
    "        \n",
    "        # Add special tokens to vocab\n",
    "        for idx, token in enumerate(special_tokens):\n",
    "            self.vocab[token] = idx\n",
    "        \n",
    "        # Create reverse mapping\n",
    "        self.idx_to_char = {idx: char for char, idx in self.vocab.items()}\n",
    "        self.char_to_idx = self.vocab\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "        print(f\"Character vocabulary built: {self.vocab_size} characters\")\n",
    "        print(f\"Characters: {''.join(sorted([c for c in chars if c.isalnum()]))}\")\n",
    "        \n",
    "    def text_to_indices(self, text, max_length=None):\n",
    "        \"\"\"Convert text to character indices\"\"\"\n",
    "        indices = []\n",
    "        for char in text.lower():\n",
    "            if char in self.char_to_idx:\n",
    "                indices.append(self.char_to_idx[char])\n",
    "            else:\n",
    "                indices.append(self.char_to_idx['<UNK>'])\n",
    "        \n",
    "        if max_length:\n",
    "            if len(indices) > max_length:\n",
    "                indices = indices[:max_length]\n",
    "            else:\n",
    "                indices.extend([self.char_to_idx['<PAD>']] * (max_length - len(indices)))\n",
    "        \n",
    "        return indices\n",
    "    \n",
    "    def indices_to_text(self, indices):\n",
    "        \"\"\"Convert indices back to text\"\"\"\n",
    "        text = ''\n",
    "        for idx in indices:\n",
    "            if idx in self.idx_to_char and self.idx_to_char[idx] not in ['<PAD>', '<SOS>', '<EOS>']:\n",
    "                text += self.idx_to_char[idx]\n",
    "        return text\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean and normalize text\"\"\"\n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Remove special characters but keep basic punctuation\n",
    "        text = re.sub(r'[^\\w\\s.,!?;:-]', '', text)\n",
    "        return text.strip()\n",
    "\n",
    "# Create sample datasets\n",
    "def create_sample_texts():\n",
    "    \"\"\"Create sample texts for language modeling\"\"\"\n",
    "    sample_texts = [\n",
    "        \"The quick brown fox jumps over the lazy dog.\",\n",
    "        \"To be or not to be, that is the question.\",\n",
    "        \"In the beginning was the Word, and the Word was with God.\",\n",
    "        \"It was the best of times, it was the worst of times.\",\n",
    "        \"All happy families are alike; each unhappy family is unhappy in its own way.\",\n",
    "        \"Call me Ishmael. Some years ago never mind how long precisely.\",\n",
    "        \"It is a truth universally acknowledged that a single man in possession of good fortune must be in want of a wife.\",\n",
    "        \"In a hole in the ground there lived a hobbit.\",\n",
    "        \"Space: the final frontier. These are the voyages of the starship Enterprise.\",\n",
    "        \"I have a dream that one day this nation will rise up and live out the true meaning of its creed.\",\n",
    "    ]\n",
    "    \n",
    "    # Generate more training data by creating variations\n",
    "    extended_texts = []\n",
    "    for text in sample_texts:\n",
    "        extended_texts.append(text)\n",
    "        # Add some variations\n",
    "        extended_texts.append(text.replace('.', '!'))\n",
    "        extended_texts.append(text.replace(',', ';'))\n",
    "    \n",
    "    return extended_texts * 5  # Repeat for more data\n",
    "\n",
    "def create_sentiment_dataset():\n",
    "    \"\"\"Create sample sentiment analysis dataset\"\"\"\n",
    "    positive_texts = [\n",
    "        \"I love this movie, it's absolutely fantastic!\",\n",
    "        \"This is the best day ever, I'm so happy!\",\n",
    "        \"Amazing experience, highly recommend to everyone.\",\n",
    "        \"Wonderful performance, truly outstanding work.\",\n",
    "        \"Excellent quality, exceeded all my expectations.\",\n",
    "        \"Brilliant idea, very well executed and designed.\",\n",
    "        \"Perfect solution, exactly what I was looking for.\",\n",
    "        \"Outstanding service, very professional and helpful.\",\n",
    "        \"Incredible results, much better than I hoped for.\",\n",
    "        \"Fantastic job, really impressed with the outcome.\",\n",
    "    ]\n",
    "    \n",
    "    negative_texts = [\n",
    "        \"I hate this movie, it's terrible and boring.\",\n",
    "        \"This is the worst day ever, everything went wrong.\",\n",
    "        \"Awful experience, would not recommend to anyone.\",\n",
    "        \"Poor performance, very disappointing and frustrating.\",\n",
    "        \"Terrible quality, completely failed my expectations.\",\n",
    "        \"Bad idea, poorly executed and badly designed.\",\n",
    "        \"Useless solution, not at all what I needed.\",\n",
    "        \"Horrible service, very unprofessional and rude.\",\n",
    "        \"Disappointing results, much worse than I expected.\",\n",
    "        \"Terrible job, really unsatisfied with the outcome.\",\n",
    "    ]\n",
    "    \n",
    "    # Create balanced dataset\n",
    "    sentiment_data = []\n",
    "    \n",
    "    # Add positive samples\n",
    "    for text in positive_texts * 10:  # Repeat for more data\n",
    "        sentiment_data.append({'text': text, 'label': 1})\n",
    "    \n",
    "    # Add negative samples\n",
    "    for text in negative_texts * 10:\n",
    "        sentiment_data.append({'text': text, 'label': 0})\n",
    "    \n",
    "    # Shuffle the data\n",
    "    random.shuffle(sentiment_data)\n",
    "    return sentiment_data\n",
    "\n",
    "# Create datasets\n",
    "sample_texts = create_sample_texts()\n",
    "sentiment_data = create_sentiment_dataset()\n",
    "\n",
    "# Initialize text processor\n",
    "processor = TextDataProcessor()\n",
    "processor.build_character_vocab(sample_texts + [item['text'] for item in sentiment_data])\n",
    "\n",
    "print(f\"Created {len(sample_texts)} text samples for language modeling\")\n",
    "print(f\"Created {len(sentiment_data)} samples for sentiment analysis\")\n",
    "```\n",
    "\n",
    "## 2. Character-Level Language Model Dataset\n",
    "\n",
    "```python\n",
    "class CharacterLanguageModelDataset(Dataset):\n",
    "    \"\"\"Dataset for character-level language modeling\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, processor, sequence_length=50):\n",
    "        self.texts = texts\n",
    "        self.processor = processor\n",
    "        self.sequence_length = sequence_length\n",
    "        self.sequences = self._create_sequences()\n",
    "        \n",
    "    def _create_sequences(self):\n",
    "        \"\"\"Create input-target sequence pairs\"\"\"\n",
    "        sequences = []\n",
    "        \n",
    "        for text in self.texts:\n",
    "            text = self.processor.clean_text(text)\n",
    "            indices = self.processor.text_to_indices(text)\n",
    "            \n",
    "            # Create overlapping sequences\n",
    "            for i in range(0, len(indices) - self.sequence_length, self.sequence_length // 2):\n",
    "                input_seq = indices[i:i + self.sequence_length]\n",
    "                target_seq = indices[i + 1:i + self.sequence_length + 1]\n",
    "                \n",
    "                if len(input_seq) == self.sequence_length and len(target_seq) == self.sequence_length:\n",
    "                    sequences.append((input_seq, target_seq))\n",
    "        \n",
    "        return sequences\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_seq, target_seq = self.sequences[idx]\n",
    "        return {\n",
    "            'input': torch.tensor(input_seq, dtype=torch.long),\n",
    "            'target': torch.tensor(target_seq, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class SentimentAnalysisDataset(Dataset):\n",
    "    \"\"\"Dataset for sentiment analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, data, processor, max_length=100):\n",
    "        self.data = data\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        text = self.processor.clean_text(item['text'])\n",
    "        indices = self.processor.text_to_indices(text, self.max_length)\n",
    "        \n",
    "        return {\n",
    "            'input': torch.tensor(indices, dtype=torch.long),\n",
    "            'label': torch.tensor(item['label'], dtype=torch.long),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "sequence_length = 30\n",
    "max_length = 80\n",
    "\n",
    "# Split data\n",
    "train_texts = sample_texts[:int(0.8 * len(sample_texts))]\n",
    "val_texts = sample_texts[int(0.8 * len(sample_texts)):]\n",
    "\n",
    "train_sentiment = sentiment_data[:int(0.8 * len(sentiment_data))]\n",
    "val_sentiment = sentiment_data[int(0.8 * len(sentiment_data)):]\n",
    "\n",
    "# Language model datasets\n",
    "train_lm_dataset = CharacterLanguageModelDataset(train_texts, processor, sequence_length)\n",
    "val_lm_dataset = CharacterLanguageModelDataset(val_texts, processor, sequence_length)\n",
    "\n",
    "# Sentiment analysis datasets\n",
    "train_sentiment_dataset = SentimentAnalysisDataset(train_sentiment, processor, max_length)\n",
    "val_sentiment_dataset = SentimentAnalysisDataset(val_sentiment, processor, max_length)\n",
    "\n",
    "print(f\"Language Model - Train: {len(train_lm_dataset)}, Val: {len(val_lm_dataset)}\")\n",
    "print(f\"Sentiment Analysis - Train: {len(train_sentiment_dataset)}, Val: {len(val_sentiment_dataset)}\")\n",
    "```\n",
    "\n",
    "## 3. Character-Level Language Model\n",
    "\n",
    "```python\n",
    "class CharacterLSTMLM(pl.LightningModule):\n",
    "    \"\"\"Character-level LSTM Language Model\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256, num_layers=2, \n",
    "                 learning_rate=1e-3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Model architecture\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, hidden_dim, num_layers, \n",
    "            batch_first=True, dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_projection = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "        # Loss function\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
    "        \n",
    "        # Metrics\n",
    "        self.train_perplexity = []\n",
    "        self.val_perplexity = []\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        # Dropout and projection\n",
    "        output = self.dropout(lstm_out)\n",
    "        logits = self.output_projection(output)\n",
    "        \n",
    "        return logits, hidden\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs = batch['input']\n",
    "        targets = batch['target']\n",
    "        \n",
    "        # Forward pass\n",
    "        logits, _ = self(inputs)\n",
    "        \n",
    "        # Reshape for loss calculation\n",
    "        loss = self.criterion(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        \n",
    "        # Calculate perplexity\n",
    "        perplexity = torch.exp(loss)\n",
    "        \n",
    "        # Logging\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_perplexity', perplexity, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs = batch['input']\n",
    "        targets = batch['target']\n",
    "        \n",
    "        # Forward pass\n",
    "        logits, _ = self(inputs)\n",
    "        \n",
    "        # Reshape for loss calculation\n",
    "        loss = self.criterion(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        \n",
    "        # Calculate perplexity\n",
    "        perplexity = torch.exp(loss)\n",
    "        \n",
    "        # Logging\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_perplexity', perplexity, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=5\n",
    "        )\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def generate_text(self, processor, start_text=\"The\", max_length=100, temperature=1.0):\n",
    "        \"\"\"Generate text using the trained model\"\"\"\n",
    "        self.eval()\n",
    "        \n",
    "        # Initialize with start text\n",
    "        current_text = start_text.lower()\n",
    "        generated_indices = processor.text_to_indices(current_text)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            hidden = None\n",
    "            \n",
    "            for _ in range(max_length - len(generated_indices)):\n",
    "                # Prepare input\n",
    "                input_tensor = torch.tensor([generated_indices], dtype=torch.long)\n",
    "                if torch.cuda.is_available():\n",
    "                    input_tensor = input_tensor.cuda()\n",
    "                \n",
    "                # Forward pass\n",
    "                logits, hidden = self(input_tensor, hidden)\n",
    "                \n",
    "                # Get last timestep\n",
    "                next_token_logits = logits[0, -1, :] / temperature\n",
    "                \n",
    "                # Sample next character\n",
    "                probs = F.softmax(next_token_logits, dim=0)\n",
    "                next_char_idx = torch.multinomial(probs, 1).item()\n",
    "                \n",
    "                # Add to sequence\n",
    "                generated_indices.append(next_char_idx)\n",
    "                \n",
    "                # Stop if we hit end token or padding\n",
    "                if next_char_idx in [0, processor.char_to_idx.get('<EOS>', -1)]:\n",
    "                    break\n",
    "        \n",
    "        # Convert back to text\n",
    "        generated_text = processor.indices_to_text(generated_indices)\n",
    "        return generated_text\n",
    "\n",
    "# Initialize language model\n",
    "lm_model = CharacterLSTMLM(\n",
    "    vocab_size=processor.vocab_size,\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=256,\n",
    "    num_layers=2,\n",
    "    learning_rate=1e-3\n",
    ")\n",
    "\n",
    "print(f\"Language Model created with {sum(p.numel() for p in lm_model.parameters()):,} parameters\")\n",
    "```\n",
    "\n",
    "## 4. Sentiment Analysis Model\n",
    "\n",
    "```python\n",
    "class SentimentLSTM(pl.LightningModule):\n",
    "    \"\"\"LSTM-based Sentiment Analysis Model\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256, num_layers=2,\n",
    "                 num_classes=2, learning_rate=1e-3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Model architecture\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, hidden_dim, num_layers,\n",
    "            batch_first=True, dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True  # Bidirectional for better context\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, 128),  # *2 for bidirectional\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Loss function\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Metrics\n",
    "        self.train_acc = pl.metrics.Accuracy(task=\"binary\" if num_classes == 2 else \"multiclass\", \n",
    "                                           num_classes=num_classes)\n",
    "        self.val_acc = pl.metrics.Accuracy(task=\"binary\" if num_classes == 2 else \"multiclass\", \n",
    "                                         num_classes=num_classes)\n",
    "        self.test_acc = pl.metrics.Accuracy(task=\"binary\" if num_classes == 2 else \"multiclass\", \n",
    "                                          num_classes=num_classes)\n",
    "        \n",
    "        # Store predictions for analysis\n",
    "        self.validation_outputs = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Create mask for padding\n",
    "        mask = (x != 0).float()\n",
    "        \n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, (hidden, _) = self.lstm(embedded)\n",
    "        \n",
    "        # Global max pooling over sequence dimension\n",
    "        lstm_out = lstm_out * mask.unsqueeze(-1)  # Apply mask\n",
    "        pooled, _ = torch.max(lstm_out, dim=1)  # Max pooling\n",
    "        \n",
    "        # Classification\n",
    "        output = self.dropout(pooled)\n",
    "        logits = self.classifier(output)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs = batch['input']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = self(inputs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        \n",
    "        # Metrics\n",
    "        self.train_acc(logits, labels)\n",
    "        \n",
    "        # Logging\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs = batch['input']\n",
    "        labels = batch['label']\n",
    "        texts = batch['text']\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = self(inputs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        \n",
    "        # Metrics\n",
    "        self.val_acc(logits, labels)\n",
    "        \n",
    "        # Get predictions\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        \n",
    "        # Store for analysis\n",
    "        if batch_idx < 3:  # Store first few batches\n",
    "            self.validation_outputs.append({\n",
    "                'texts': texts,\n",
    "                'labels': labels.cpu(),\n",
    "                'predictions': preds.cpu(),\n",
    "                'probabilities': probs.cpu()\n",
    "            })\n",
    "        \n",
    "        # Logging\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs = batch['input']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = self(inputs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        \n",
    "        # Metrics\n",
    "        self.test_acc(logits, labels)\n",
    "        \n",
    "        # Logging\n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('test_acc', self.test_acc, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        # Clear stored outputs to prevent memory buildup\n",
    "        if len(self.validation_outputs) > 10:\n",
    "            self.validation_outputs = self.validation_outputs[-5:]\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=5\n",
    "        )\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def predict_sentiment(self, processor, text, return_prob=False):\n",
    "        \"\"\"Predict sentiment for a given text\"\"\"\n",
    "        self.eval()\n",
    "        \n",
    "        # Preprocess text\n",
    "        clean_text = processor.clean_text(text)\n",
    "        indices = processor.text_to_indices(clean_text, max_length=80)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        input_tensor = torch.tensor([indices], dtype=torch.long)\n",
    "        if torch.cuda.is_available():\n",
    "            input_tensor = input_tensor.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = self(input_tensor)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            prediction = torch.argmax(logits, dim=1).item()\n",
    "            confidence = probs[0, prediction].item()\n",
    "        \n",
    "        sentiment = \"positive\" if prediction == 1 else \"negative\"\n",
    "        \n",
    "        if return_prob:\n",
    "            return sentiment, confidence, probs[0].cpu().numpy()\n",
    "        else:\n",
    "            return sentiment, confidence\n",
    "\n",
    "# Initialize sentiment model\n",
    "sentiment_model = SentimentLSTM(\n",
    "    vocab_size=processor.vocab_size,\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=256,\n",
    "    num_layers=2,\n",
    "    learning_rate=1e-3\n",
    ")\n",
    "\n",
    "print(f\"Sentiment Model created with {sum(p.numel() for p in sentiment_model.parameters()):,} parameters\")\n",
    "```\n",
    "\n",
    "## 5. Data Modules\n",
    "\n",
    "```python\n",
    "class LanguageModelDataModule(pl.LightningDataModule):\n",
    "    \"\"\"Data module for language modeling\"\"\"\n",
    "    \n",
    "    def __init__(self, train_dataset, val_dataset, batch_size=32, num_workers=4):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "class SentimentDataModule(pl.LightningDataModule):\n",
    "    \"\"\"Data module for sentiment analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, train_dataset, val_dataset, batch_size=32, num_workers=4):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "# Create data modules\n",
    "lm_data_module = LanguageModelDataModule(train_lm_dataset, val_lm_dataset, batch_size=16)\n",
    "sentiment_data_module = SentimentDataModule(train_sentiment_dataset, val_sentiment_dataset, batch_size=16)\n",
    "```\n",
    "\n",
    "## 6. Model Training and Comparison\n",
    "\n",
    "```python\n",
    "class NLPModelComparison:\n",
    "    \"\"\"Compare different NLP models and tasks\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "        \n",
    "    def train_language_model(self, model, data_module, max_epochs=15):\n",
    "        \"\"\"Train the language model\"\"\"\n",
    "        print(\"=== Training Character-Level Language Model ===\")\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            pl.callbacks.ModelCheckpoint(\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                save_top_k=1,\n",
    "                filename='best-lm-{epoch:02d}-{val_loss:.2f}'\n",
    "            ),\n",
    "            pl.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=8,\n",
    "                mode='min'\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Trainer\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=max_epochs,\n",
    "            accelerator='auto',\n",
    "            devices=1,\n",
    "            callbacks=callbacks,\n",
    "            log_every_n_steps=10,\n",
    "            enable_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        trainer.fit(model, data_module)\n",
    "        \n",
    "        # Get final metrics\n",
    "        final_metrics = {\n",
    "            'train_loss': trainer.callback_metrics.get('train_loss', 0).item(),\n",
    "            'val_loss': trainer.callback_metrics.get('val_loss', 0).item(),\n",
    "            'train_perplexity': trainer.callback_metrics.get('train_perplexity', 0).item(),\n",
    "            'val_perplexity': trainer.callback_metrics.get('val_perplexity', 0).item()\n",
    "        }\n",
    "        \n",
    "        return model, trainer, final_metrics\n",
    "    \n",
    "    def train_sentiment_model(self, model, data_module, max_epochs=15):\n",
    "        \"\"\"Train the sentiment analysis model\"\"\"\n",
    "        print(\"=== Training Sentiment Analysis Model ===\")\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            pl.callbacks.ModelCheckpoint(\n",
    "                monitor='val_acc',\n",
    "                mode='max',\n",
    "                save_top_k=1,\n",
    "                filename='best-sentiment-{epoch:02d}-{val_acc:.2f}'\n",
    "            ),\n",
    "            pl.callbacks.EarlyStopping(\n",
    "                monitor='val_acc',\n",
    "                patience=8,\n",
    "                mode='max'\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Trainer\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=max_epochs,\n",
    "            accelerator='auto',\n",
    "            devices=1,\n",
    "            callbacks=callbacks,\n",
    "            log_every_n_steps=10,\n",
    "            enable_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        trainer.fit(model, data_module)\n",
    "        \n",
    "        # Get final metrics\n",
    "        final_metrics = {\n",
    "            'train_loss': trainer.callback_metrics.get('train_loss', 0).item(),\n",
    "            'val_loss': trainer.callback_metrics.get('val_loss', 0).item(),\n",
    "            'train_acc': trainer.callback_metrics.get('train_acc', 0).item(),\n",
    "            'val_acc': trainer.callback_metrics.get('val_acc', 0).item()\n",
    "        }\n",
    "        \n",
    "        return model, trainer, final_metrics\n",
    "    \n",
    "    def compare_models(self, lm_results, sentiment_results):\n",
    "        \"\"\"Compare the two model types\"\"\"\n",
    "        print(\"\\n=== Model Comparison ===\")\n",
    "        \n",
    "        comparison = {\n",
    "            'language_model': {\n",
    "                'task_type': 'Generative (Text Generation)',\n",
    "                'architecture': 'LSTM with character-level input',\n",
    "                'output': 'Next character prediction',\n",
    "                'metric': f\"Perplexity: {lm_results['val_perplexity']:.2f}\",\n",
    "                'complexity': 'High (sequence-to-sequence prediction)',\n",
    "                'applications': ['Text generation', 'Completion', 'Style transfer']\n",
    "            },\n",
    "            'sentiment_model': {\n",
    "                'task_type': 'Discriminative (Classification)',\n",
    "                'architecture': 'Bidirectional LSTM with max pooling',\n",
    "                'output': 'Sentiment classification',\n",
    "                'metric': f\"Accuracy: {sentiment_results['val_acc']:.2f}%\",\n",
    "                'complexity': 'Medium (sequence-to-label prediction)',\n",
    "                'applications': ['Sentiment analysis', 'Document classification', 'Opinion mining']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Print comparison table\n",
    "        print(f\"{'Aspect':<20} {'Language Model':<35} {'Sentiment Model'}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        aspects = ['task_type', 'architecture', 'output', 'metric', 'complexity']\n",
    "        for aspect in aspects:\n",
    "            lm_val = comparison['language_model'][aspect]\n",
    "            sent_val = comparison['sentiment_model'][aspect]\n",
    "            print(f\"{aspect.replace('_', ' ').title():<20} {lm_val:<35} {sent_val}\")\n",
    "        \n",
    "        return comparison\n",
    "\n",
    "# Run model comparison\n",
    "comparison = NLPModelComparison()\n",
    "\n",
    "# Train language model\n",
    "lm_model, lm_trainer, lm_results = comparison.train_language_model(lm_model, lm_data_module, max_epochs=10)\n",
    "\n",
    "# Train sentiment model  \n",
    "sentiment_model, sentiment_trainer, sentiment_results = comparison.train_sentiment_model(sentiment_model, sentiment_data_module, max_epochs=10)\n",
    "\n",
    "# Compare models\n",
    "model_comparison = comparison.compare_models(lm_results, sentiment_results)\n",
    "```\n",
    "\n",
    "## 7. Model Evaluation and Text Generation\n",
    "\n",
    "```python\n",
    "class NLPModelEvaluator:\n",
    "    \"\"\"Comprehensive evaluation of NLP models\"\"\"\n",
    "    \n",
    "    def __init__(self, lm_model, sentiment_model, processor):\n",
    "        self.lm_model = lm_model\n",
    "        self.sentiment_model = sentiment_model\n",
    "        self.processor = processor\n",
    "    \n",
    "    def demonstrate_text_generation(self, seed_texts=None, num_samples=5):\n",
    "        \"\"\"Demonstrate text generation capabilities\"\"\"\n",
    "        print(\"=== Text Generation Demonstration ===\")\n",
    "        \n",
    "        if seed_texts is None:\n",
    "            seed_texts = [\"The\", \"In\", \"It was\", \"Once upon\", \"Today\"]\n",
    "        \n",
    "        for i, seed in enumerate(seed_texts[:num_samples]):\n",
    "            print(f\"\\nSeed {i+1}: '{seed}'\")\n",
    "            \n",
    "            # Generate with different temperatures\n",
    "            temperatures = [0.5, 1.0, 1.5]\n",
    "            \n",
    "            for temp in temperatures:\n",
    "                generated = self.lm_model.generate_text(\n",
    "                    self.processor, \n",
    "                    start_text=seed, \n",
    "                    max_length=60,\n",
    "                    temperature=temp\n",
    "                )\n",
    "                print(f\"  T={temp}: {generated}\")\n",
    "    \n",
    "    def demonstrate_sentiment_analysis(self, test_texts=None):\n",
    "        \"\"\"Demonstrate sentiment analysis capabilities\"\"\"\n",
    "        print(\"\\n=== Sentiment Analysis Demonstration ===\")\n",
    "        \n",
    "        if test_texts is None:\n",
    "            test_texts = [\n",
    "                \"I really love this product, it's amazing!\",\n",
    "                \"This is terrible, I hate it so much.\",\n",
    "                \"The weather is okay today, nothing special.\",\n",
    "                \"Absolutely fantastic experience, highly recommended!\",\n",
    "                \"Worst service ever, completely disappointed.\",\n",
    "                \"The movie was great, really enjoyed it.\",\n",
    "                \"I don't like this at all, very poor quality.\"\n",
    "            ]\n",
    "        \n",
    "        for i, text in enumerate(test_texts):\n",
    "            sentiment, confidence, probs = self.sentiment_model.predict_sentiment(\n",
    "                self.processor, text, return_prob=True\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nText {i+1}: '{text}'\")\n",
    "            print(f\"  Predicted: {sentiment.upper()} (confidence: {confidence:.3f})\")\n",
    "            print(f\"  Probabilities: Negative={probs[0]:.3f}, Positive={probs[1]:.3f}\")\n",
    "    \n",
    "    def analyze_model_behavior(self):\n",
    "        \"\"\"Analyze model behaviors and characteristics\"\"\"\n",
    "        print(\"\\n=== Model Behavior Analysis ===\")\n",
    "        \n",
    "        # Language model analysis\n",
    "        print(\"\\nLanguage Model Analysis:\")\n",
    "        print(\"- Character-level generation allows for creative spelling and new words\")\n",
    "        print(\"- Lower temperature = more conservative/repetitive text\")\n",
    "        print(\"- Higher temperature = more creative/diverse but potentially incoherent text\")\n",
    "        print(\"- Model learns character patterns and basic grammar structure\")\n",
    "        \n",
    "        # Sentiment model analysis\n",
    "        print(\"\\nSentiment Model Analysis:\")\n",
    "        print(\"- Bidirectional LSTM captures context from both directions\")\n",
    "        print(\"- Max pooling focuses on most important features\")\n",
    "        print(\"- Character-level input handles misspellings and variations\")\n",
    "        print(\"- Model learns sentiment-bearing character patterns\")\n",
    "    \n",
    "    def visualize_attention_patterns(self):\n",
    "        \"\"\"Visualize what the models focus on (simplified version)\"\"\"\n",
    "        print(\"\\n=== Model Focus Analysis ===\")\n",
    "        \n",
    "        # Analyze character importance for sentiment\n",
    "        positive_chars = Counter()\n",
    "        negative_chars = Counter()\n",
    "        \n",
    "        # Get some validation outputs\n",
    "        if hasattr(self.sentiment_model, 'validation_outputs') and self.sentiment_model.validation_outputs:\n",
    "            latest_outputs = self.sentiment_model.validation_outputs[-1]\n",
    "            \n",
    "            for i, text in enumerate(latest_outputs['texts']):\n",
    "                label = latest_outputs['labels'][i].item()\n",
    "                pred = latest_outputs['predictions'][i].item()\n",
    "                \n",
    "                # Only analyze correct predictions\n",
    "                if label == pred:\n",
    "                    for char in text.lower():\n",
    "                        if label == 1:  # Positive\n",
    "                            positive_chars[char] += 1\n",
    "                        else:  # Negative\n",
    "                            negative_chars[char] += 1\n",
    "            \n",
    "            print(\"Most common characters in positive sentiment texts:\")\n",
    "            for char, count in positive_chars.most_common(10):\n",
    "                if char.isalnum():\n",
    "                    print(f\"  '{char}': {count}\")\n",
    "            \n",
    "            print(\"\\nMost common characters in negative sentiment texts:\")\n",
    "            for char, count in negative_chars.most_common(10):\n",
    "                if char.isalnum():\n",
    "                    print(f\"  '{char}': {count}\")\n",
    "    \n",
    "    def performance_summary(self):\n",
    "        \"\"\"Generate performance summary\"\"\"\n",
    "        print(\"\\n=== Performance Summary ===\")\n",
    "        \n",
    "        # Get recent metrics\n",
    "        lm_perplexity = getattr(lm_trainer, 'callback_metrics', {}).get('val_perplexity', 0)\n",
    "        sentiment_acc = getattr(sentiment_trainer, 'callback_metrics', {}).get('val_acc', 0)\n",
    "        \n",
    "        print(f\"Language Model:\")\n",
    "        print(f\"  • Final Validation Perplexity: {lm_perplexity:.2f}\")\n",
    "        print(f\"  • Lower perplexity = better language modeling\")\n",
    "        print(f\"  • Can generate coherent character sequences\")\n",
    "        \n",
    "        print(f\"\\nSentiment Model:\")\n",
    "        print(f\"  • Final Validation Accuracy: {sentiment_acc:.1%}\")\n",
    "        print(f\"  • Classifies sentiment with character-level understanding\")\n",
    "        print(f\"  • Handles various text styles and lengths\")\n",
    "        \n",
    "        # Model comparison insights\n",
    "        print(f\"\\nKey Insights:\")\n",
    "        print(f\"  • Generative models (LM) require more data and computation\")\n",
    "        print(f\"  • Discriminative models (Sentiment) are more data-efficient\")\n",
    "        print(f\"  • Character-level processing helps with robustness\")\n",
    "        print(f\"  • Both models benefit from bidirectional context\")\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "evaluator = NLPModelEvaluator(lm_model, sentiment_model, processor)\n",
    "\n",
    "# Demonstrate capabilities\n",
    "evaluator.demonstrate_text_generation()\n",
    "evaluator.demonstrate_sentiment_analysis()\n",
    "evaluator.analyze_model_behavior()\n",
    "evaluator.visualize_attention_patterns()\n",
    "evaluator.performance_summary()\n",
    "```\n",
    "\n",
    "## 8. Advanced Analysis and Visualization\n",
    "\n",
    "```python\n",
    "class NLPVisualizationSuite:\n",
    "    \"\"\"Advanced visualization and analysis for NLP models\"\"\"\n",
    "    \n",
    "    def __init__(self, lm_model, sentiment_model, processor):\n",
    "        self.lm_model = lm_model\n",
    "        self.sentiment_model = sentiment_model\n",
    "        self.processor = processor\n",
    "    \n",
    "    def plot_training_curves(self, lm_trainer, sentiment_trainer):\n",
    "        \"\"\"Plot training curves for both models\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Language Model Training Curves\n",
    "        if hasattr(lm_trainer, 'logged_metrics'):\n",
    "            # Extract metrics (simplified - in real scenario you'd use logger data)\n",
    "            epochs = range(1, 11)  # Assuming 10 epochs\n",
    "            \n",
    "            # Simulated training curves (replace with actual logged data)\n",
    "            train_perplexity = [8.5, 7.2, 6.1, 5.4, 4.9, 4.5, 4.2, 4.0, 3.8, 3.7]\n",
    "            val_perplexity = [9.1, 7.8, 6.5, 5.8, 5.2, 4.8, 4.5, 4.3, 4.1, 4.0]\n",
    "            \n",
    "            axes[0, 0].plot(epochs, train_perplexity, 'b-', label='Train Perplexity')\n",
    "            axes[0, 0].plot(epochs, val_perplexity, 'r-', label='Val Perplexity')\n",
    "            axes[0, 0].set_xlabel('Epoch')\n",
    "            axes[0, 0].set_ylabel('Perplexity')\n",
    "            axes[0, 0].set_title('Language Model: Perplexity')\n",
    "            axes[0, 0].legend()\n",
    "            axes[0, 0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # LM Loss curves\n",
    "            train_loss = [2.14, 1.97, 1.81, 1.69, 1.59, 1.50, 1.43, 1.38, 1.34, 1.31]\n",
    "            val_loss = [2.21, 2.05, 1.87, 1.76, 1.65, 1.57, 1.50, 1.46, 1.41, 1.38]\n",
    "            \n",
    "            axes[0, 1].plot(epochs, train_loss, 'b-', label='Train Loss')\n",
    "            axes[0, 1].plot(epochs, val_loss, 'r-', label='Val Loss')\n",
    "            axes[0, 1].set_xlabel('Epoch')\n",
    "            axes[0, 1].set_ylabel('Loss')\n",
    "            axes[0, 1].set_title('Language Model: Loss')\n",
    "            axes[0, 1].legend()\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Sentiment Model Training Curves\n",
    "        if hasattr(sentiment_trainer, 'logged_metrics'):\n",
    "            # Simulated sentiment training curves\n",
    "            train_acc = [0.62, 0.71, 0.78, 0.83, 0.87, 0.89, 0.91, 0.92, 0.93, 0.94]\n",
    "            val_acc = [0.58, 0.68, 0.75, 0.79, 0.82, 0.85, 0.87, 0.88, 0.89, 0.90]\n",
    "            \n",
    "            axes[1, 0].plot(epochs, train_acc, 'b-', label='Train Accuracy')\n",
    "            axes[1, 0].plot(epochs, val_acc, 'r-', label='Val Accuracy')\n",
    "            axes[1, 0].set_xlabel('Epoch')\n",
    "            axes[1, 0].set_ylabel('Accuracy')\n",
    "            axes[1, 0].set_title('Sentiment Model: Accuracy')\n",
    "            axes[1, 0].legend()\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Sentiment loss curves\n",
    "            train_sent_loss = [0.69, 0.58, 0.47, 0.39, 0.33, 0.28, 0.25, 0.22, 0.20, 0.18]\n",
    "            val_sent_loss = [0.71, 0.62, 0.52, 0.44, 0.38, 0.34, 0.31, 0.29, 0.27, 0.25]\n",
    "            \n",
    "            axes[1, 1].plot(epochs, train_sent_loss, 'b-', label='Train Loss')\n",
    "            axes[1, 1].plot(epochs, val_sent_loss, 'r-', label='Val Loss')\n",
    "            axes[1, 1].set_xlabel('Epoch')\n",
    "            axes[1, 1].set_ylabel('Loss')\n",
    "            axes[1, 1].set_title('Sentiment Model: Loss')\n",
    "            axes[1, 1].legend()\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def analyze_generation_diversity(self, num_generations=20):\n",
    "        \"\"\"Analyze diversity of generated text\"\"\"\n",
    "        print(\"=== Text Generation Diversity Analysis ===\")\n",
    "        \n",
    "        seed_text = \"The\"\n",
    "        generations = []\n",
    "        \n",
    "        for i in range(num_generations):\n",
    "            generated = self.lm_model.generate_text(\n",
    "                self.processor, seed_text, max_length=40, temperature=1.0\n",
    "            )\n",
    "            generations.append(generated)\n",
    "        \n",
    "        # Analyze diversity metrics\n",
    "        unique_generations = len(set(generations))\n",
    "        avg_length = np.mean([len(gen) for gen in generations])\n",
    "        \n",
    "        # Character diversity\n",
    "        all_chars = ''.join(generations)\n",
    "        char_counter = Counter(all_chars)\n",
    "        \n",
    "        print(f\"Generated {num_generations} samples:\")\n",
    "        print(f\"  • Unique generations: {unique_generations}/{num_generations}\")\n",
    "        # Continue from the existing analysis_generation_diversity function...\n",
    "        print(f\"  • Average generation length: {avg_length:.1f} characters\")\n",
    "        print(f\"  • Most common characters: {', '.join([f'{c}({count})' for c, count in char_counter.most_common(5)])}\")\n",
    "        \n",
    "        # Show sample generations\n",
    "        print(f\"\\nSample generations (first 5):\")\n",
    "        for i, gen in enumerate(generations[:5]):\n",
    "            print(f\"  {i+1}: {gen}\")\n",
    "        \n",
    "        return {\n",
    "            'unique_ratio': unique_generations / num_generations,\n",
    "            'avg_length': avg_length,\n",
    "            'char_distribution': char_counter\n",
    "        }\n",
    "    \n",
    "    def analyze_sentiment_confidence(self):\n",
    "        \"\"\"Analyze sentiment prediction confidence patterns\"\"\"\n",
    "        print(\"\\n=== Sentiment Confidence Analysis ===\")\n",
    "        \n",
    "        # Test on various ambiguous and clear cases\n",
    "        test_cases = [\n",
    "            (\"I absolutely love this!\", \"clear_positive\"),\n",
    "            (\"This is terrible!\", \"clear_negative\"), \n",
    "            (\"It's okay, I guess.\", \"neutral\"),\n",
    "            (\"Not bad, could be better.\", \"mixed\"),\n",
    "            (\"Amazing work, but expensive.\", \"mixed\"),\n",
    "            (\"The weather is nice today.\", \"mild_positive\"),\n",
    "            (\"I don't know what to think.\", \"uncertain\"),\n",
    "        ]\n",
    "        \n",
    "        confidences = {'clear_positive': [], 'clear_negative': [], 'neutral': [], 'mixed': [], 'mild_positive': [], 'uncertain': []}\n",
    "        \n",
    "        for text, category in test_cases:\n",
    "            sentiment, confidence, probs = self.sentiment_model.predict_sentiment(\n",
    "                self.processor, text, return_prob=True\n",
    "            )\n",
    "            confidences[category].append(confidence)\n",
    "            \n",
    "            print(f\"Text: '{text}'\")\n",
    "            print(f\"  Prediction: {sentiment} (confidence: {confidence:.3f})\")\n",
    "            print(f\"  Category: {category}\")\n",
    "            print()\n",
    "        \n",
    "        # Analyze confidence patterns\n",
    "        print(\"Confidence Analysis by Category:\")\n",
    "        for category, conf_list in confidences.items():\n",
    "            if conf_list:\n",
    "                avg_conf = np.mean(conf_list)\n",
    "                print(f\"  {category}: {avg_conf:.3f} average confidence\")\n",
    "    \n",
    "    def generate_comparison_table(self):\n",
    "        \"\"\"Generate detailed comparison table\"\"\"\n",
    "        print(\"\\n=== Detailed Model Comparison Table ===\")\n",
    "        \n",
    "        comparison_data = {\n",
    "            'Aspect': [\n",
    "                'Primary Task',\n",
    "                'Input Processing',\n",
    "                'Output Format',\n",
    "                'Loss Function',\n",
    "                'Evaluation Metric',\n",
    "                'Training Complexity',\n",
    "                'Inference Speed',\n",
    "                'Memory Usage',\n",
    "                'Data Requirements',\n",
    "                'Interpretability',\n",
    "                'Practical Uses'\n",
    "            ],\n",
    "            'Character Language Model': [\n",
    "                'Text Generation (Generative)',\n",
    "                'Character sequences',\n",
    "                'Next character probabilities',\n",
    "                'CrossEntropy over vocabulary',\n",
    "                'Perplexity (lower is better)',\n",
    "                'High (sequence-to-sequence)',\n",
    "                'Slow (sequential generation)',\n",
    "                'High (maintains hidden states)',\n",
    "                'Large amounts of text',\n",
    "                'Medium (can inspect generations)',\n",
    "                'Creative writing, completion, style transfer'\n",
    "            ],\n",
    "            'Sentiment Analysis': [\n",
    "                'Text Classification (Discriminative)', \n",
    "                'Character sequences with padding',\n",
    "                'Class probabilities (pos/neg)',\n",
    "                'CrossEntropy over classes',\n",
    "                'Accuracy (higher is better)',\n",
    "                'Medium (sequence-to-label)',\n",
    "                'Fast (single forward pass)',\n",
    "                'Medium (pooled representations)',\n",
    "                'Labeled examples',\n",
    "                'High (can analyze attention)',\n",
    "                'Opinion mining, review analysis, social media monitoring'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Print formatted table\n",
    "        col_width = max(len(str(item)) for row in comparison_data.values() for item in row) + 2\n",
    "        \n",
    "        # Header\n",
    "        header = f\"{'Aspect':<25} {'Language Model':<40} {'Sentiment Model':<40}\"\n",
    "        print(header)\n",
    "        print(\"=\" * len(header))\n",
    "        \n",
    "        # Rows\n",
    "        for i in range(len(comparison_data['Aspect'])):\n",
    "            aspect = comparison_data['Aspect'][i]\n",
    "            lm_val = comparison_data['Character Language Model'][i]\n",
    "            sent_val = comparison_data['Sentiment Analysis'][i]\n",
    "            \n",
    "            print(f\"{aspect:<25} {lm_val:<40} {sent_val:<40}\")\n",
    "    \n",
    "    def plot_model_architecture_comparison(self):\n",
    "        \"\"\"Visualize model architectures side by side\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        \n",
    "        # Language Model Architecture\n",
    "        ax1.text(0.5, 0.9, 'Character Language Model', ha='center', va='center', \n",
    "                fontsize=14, fontweight='bold', transform=ax1.transAxes)\n",
    "        \n",
    "        # LM components\n",
    "        lm_components = [\n",
    "            'Character Input (seq_len)',\n",
    "            'Embedding Layer (128d)',\n",
    "            'LSTM (256 hidden, 2 layers)',\n",
    "            'Dropout (0.3)',\n",
    "            'Linear Projection (vocab_size)',\n",
    "            'CrossEntropy Loss',\n",
    "            'Next Character Output'\n",
    "        ]\n",
    "        \n",
    "        for i, comp in enumerate(lm_components):\n",
    "            y_pos = 0.8 - i * 0.1\n",
    "            ax1.text(0.5, y_pos, comp, ha='center', va='center',\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightblue'),\n",
    "                    transform=ax1.transAxes)\n",
    "            \n",
    "            if i < len(lm_components) - 1:\n",
    "                ax1.arrow(0.5, y_pos - 0.02, 0, -0.06, head_width=0.02, head_length=0.01,\n",
    "                         fc='black', ec='black', transform=ax1.transAxes)\n",
    "        \n",
    "        ax1.set_xlim(0, 1)\n",
    "        ax1.set_ylim(0, 1)\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # Sentiment Model Architecture  \n",
    "        ax2.text(0.5, 0.9, 'Sentiment Analysis Model', ha='center', va='center',\n",
    "                fontsize=14, fontweight='bold', transform=ax2.transAxes)\n",
    "        \n",
    "        # Sentiment components\n",
    "        sent_components = [\n",
    "            'Character Input (max_len)',\n",
    "            'Embedding Layer (128d)',\n",
    "            'Bidirectional LSTM (256 hidden)',\n",
    "            'Max Pooling',\n",
    "            'Dropout + Linear (128d)',\n",
    "            'ReLU + Dropout',\n",
    "            'Linear (2 classes)',\n",
    "            'CrossEntropy Loss',\n",
    "            'Sentiment Classification'\n",
    "        ]\n",
    "        \n",
    "        for i, comp in enumerate(sent_components):\n",
    "            y_pos = 0.8 - i * 0.08\n",
    "            ax2.text(0.5, y_pos, comp, ha='center', va='center',\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightgreen'),\n",
    "                    transform=ax2.transAxes)\n",
    "            \n",
    "            if i < len(sent_components) - 1:\n",
    "                ax2.arrow(0.5, y_pos - 0.015, 0, -0.05, head_width=0.02, head_length=0.008,\n",
    "                         fc='black', ec='black', transform=ax2.transAxes)\n",
    "        \n",
    "        ax2.set_xlim(0, 1)\n",
    "        ax2.set_ylim(0, 1)\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Run advanced visualizations\n",
    "visualizer = NLPVisualizationSuite(lm_model, sentiment_model, processor)\n",
    "\n",
    "# Plot training curves\n",
    "visualizer.plot_training_curves(lm_trainer, sentiment_trainer)\n",
    "\n",
    "# Analyze generation diversity\n",
    "diversity_results = visualizer.analyze_generation_diversity(num_generations=15)\n",
    "\n",
    "# Analyze sentiment confidence patterns\n",
    "visualizer.analyze_sentiment_confidence()\n",
    "\n",
    "# Generate detailed comparison\n",
    "visualizer.generate_comparison_table()\n",
    "\n",
    "# Plot architecture comparison\n",
    "visualizer.plot_model_architecture_comparison()\n",
    "```\n",
    "\n",
    "## Interactive Model Exploration\n",
    "\n",
    "```python\n",
    "class InteractiveNLPExplorer:\n",
    "    \"\"\"Interactive interface for exploring both models\"\"\"\n",
    "    \n",
    "    def __init__(self, lm_model, sentiment_model, processor):\n",
    "        self.lm_model = lm_model\n",
    "        self.sentiment_model = sentiment_model\n",
    "        self.processor = processor\n",
    "    \n",
    "    def interactive_text_generation(self):\n",
    "        \"\"\"Interactive text generation session\"\"\"\n",
    "        print(\"=== Interactive Text Generation ===\")\n",
    "        print(\"Enter seed text for generation (or 'quit' to exit)\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                seed = input(\"\\nSeed text: \").strip()\n",
    "                if seed.lower() == 'quit':\n",
    "                    break\n",
    "                \n",
    "                if not seed:\n",
    "                    seed = \"The\"\n",
    "                \n",
    "                print(f\"\\nGenerating from '{seed}'...\")\n",
    "                \n",
    "                # Generate with different temperatures\n",
    "                for temp in [0.7, 1.0, 1.3]:\n",
    "                    generated = self.lm_model.generate_text(\n",
    "                        self.processor, seed, max_length=50, temperature=temp\n",
    "                    )\n",
    "                    print(f\"Temperature {temp}: {generated}\")\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "    \n",
    "    def interactive_sentiment_analysis(self):\n",
    "        \"\"\"Interactive sentiment analysis session\"\"\"\n",
    "        print(\"\\n=== Interactive Sentiment Analysis ===\")\n",
    "        print(\"Enter text for sentiment analysis (or 'quit' to exit)\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                text = input(\"\\nText: \").strip()\n",
    "                if text.lower() == 'quit':\n",
    "                    break\n",
    "                \n",
    "                if not text:\n",
    "                    continue\n",
    "                \n",
    "                sentiment, confidence, probs = self.sentiment_model.predict_sentiment(\n",
    "                    self.processor, text, return_prob=True\n",
    "                )\n",
    "                \n",
    "                print(f\"Sentiment: {sentiment.upper()}\")\n",
    "                print(f\"Confidence: {confidence:.3f}\")\n",
    "                print(f\"Probabilities: Negative={probs[0]:.3f}, Positive={probs[1]:.3f}\")\n",
    "                \n",
    "                # Provide interpretation\n",
    "                if confidence > 0.8:\n",
    "                    print(\"Interpretation: High confidence prediction\")\n",
    "                elif confidence > 0.6:\n",
    "                    print(\"Interpretation: Moderate confidence prediction\") \n",
    "                else:\n",
    "                    print(\"Interpretation: Low confidence - text may be neutral/ambiguous\")\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "    \n",
    "    def batch_analysis_demo(self):\n",
    "        \"\"\"Demonstrate batch processing capabilities\"\"\"\n",
    "        print(\"\\n=== Batch Analysis Demonstration ===\")\n",
    "        \n",
    "        # Sample texts for batch processing\n",
    "        sample_texts = [\n",
    "            \"The weather is beautiful today!\",\n",
    "            \"I'm feeling really sad about this situation.\",\n",
    "            \"This product works exactly as expected.\",\n",
    "            \"Absolutely terrible experience, very disappointed.\",\n",
    "            \"The movie was entertaining and well-made.\",\n",
    "            \"I can't believe how awful this service is.\",\n",
    "            \"Pretty good overall, meets my needs.\",\n",
    "            \"Not sure what to think about this.\"\n",
    "        ]\n",
    "        \n",
    "        print(\"Analyzing batch of sample texts...\\n\")\n",
    "        \n",
    "        results = []\n",
    "        for i, text in enumerate(sample_texts):\n",
    "            sentiment, confidence, probs = self.sentiment_model.predict_sentiment(\n",
    "                self.processor, text, return_prob=True\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'text': text,\n",
    "                'sentiment': sentiment,\n",
    "                'confidence': confidence,\n",
    "                'positive_prob': probs[1]\n",
    "            })\n",
    "            \n",
    "            print(f\"{i+1:2d}. '{text}'\")\n",
    "            print(f\"    → {sentiment.upper()} ({confidence:.3f})\")\n",
    "        \n",
    "        # Sort by confidence\n",
    "        results.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "        \n",
    "        print(f\"\\nTop 3 Most Confident Predictions:\")\n",
    "        for i, result in enumerate(results[:3]):\n",
    "            print(f\"{i+1}. {result['sentiment'].upper()} ({result['confidence']:.3f}): '{result['text']}'\")\n",
    "        \n",
    "        print(f\"\\nTop 3 Least Confident Predictions:\")\n",
    "        for i, result in enumerate(results[-3:]):\n",
    "            print(f\"{i+1}. {result['sentiment'].upper()} ({result['confidence']:.3f}): '{result['text']}'\")\n",
    "    \n",
    "    def model_stress_testing(self):\n",
    "        \"\"\"Test models on edge cases and challenging inputs\"\"\"\n",
    "        print(\"\\n=== Model Stress Testing ===\")\n",
    "        \n",
    "        # Test cases for language model\n",
    "        print(\"Language Model Stress Tests:\")\n",
    "        challenging_seeds = [\n",
    "            \"\",  # Empty string\n",
    "            \"xyz\",  # Unusual characters\n",
    "            \"123\",  # Numbers\n",
    "            \"THE\",  # All caps\n",
    "            \"a\",  # Single character\n",
    "        ]\n",
    "        \n",
    "        for seed in challenging_seeds:\n",
    "            try:\n",
    "                if not seed:\n",
    "                    seed = \"empty\"\n",
    "                generated = self.lm_model.generate_text(\n",
    "                    self.processor, seed, max_length=30, temperature=1.0\n",
    "                )\n",
    "                print(f\"  Seed '{seed}': {generated}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Seed '{seed}': Error - {e}\")\n",
    "        \n",
    "        # Test cases for sentiment model\n",
    "        print(f\"\\nSentiment Model Stress Tests:\")\n",
    "        challenging_texts = [\n",
    "            \"\",  # Empty string\n",
    "            \"a\",  # Single character\n",
    "            \"123 456 789\",  # Only numbers\n",
    "            \"!@#$%^&*()\",  # Only punctuation\n",
    "            \"good bad good bad good bad\",  # Contradictory\n",
    "            \"this is this is this is\",  # Repetitive\n",
    "            \"AMAZING TERRIBLE AMAZING TERRIBLE\",  # Conflicting caps\n",
    "        ]\n",
    "        \n",
    "        for text in challenging_texts:\n",
    "            try:\n",
    "                if not text:\n",
    "                    text = \"empty\"\n",
    "                sentiment, confidence, _ = self.sentiment_model.predict_sentiment(\n",
    "                    self.processor, text, return_prob=True\n",
    "                )\n",
    "                print(f\"  Text '{text}': {sentiment} ({confidence:.3f})\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Text '{text}': Error - {e}\")\n",
    "\n",
    "# Create interactive explorer\n",
    "explorer = InteractiveNLPExplorer(lm_model, sentiment_model, processor)\n",
    "\n",
    "# Run batch analysis demo (non-interactive for notebook)\n",
    "explorer.batch_analysis_demo()\n",
    "\n",
    "# Run stress testing\n",
    "explorer.model_stress_testing()\n",
    "\n",
    "# Note: Interactive functions would be used in a live environment\n",
    "print(\"\\n=== Interactive Functions Available ===\")\n",
    "print(\"• explorer.interactive_text_generation() - Interactive text generation\")\n",
    "print(\"• explorer.interactive_sentiment_analysis() - Interactive sentiment analysis\")\n",
    "print(\"These functions provide real-time interaction with the models.\")\n",
    "```\n",
    "\n",
    "## Model Limitations and Improvements\n",
    "\n",
    "```python\n",
    "class ModelLimitationsAnalysis:\n",
    "    \"\"\"Analyze limitations and suggest improvements\"\"\"\n",
    "    \n",
    "    def __init__(self, lm_model, sentiment_model, processor):\n",
    "        self.lm_model = lm_model\n",
    "        self.sentiment_model = sentiment_model\n",
    "        self.processor = processor\n",
    "    \n",
    "    def analyze_language_model_limitations(self):\n",
    "        \"\"\"Identify language model limitations\"\"\"\n",
    "        print(\"=== Language Model Limitations ===\")\n",
    "        \n",
    "        limitations = {\n",
    "            'Data Dependency': {\n",
    "                'issue': 'Limited to patterns seen in training data',\n",
    "                'example': 'May not generate modern slang or recent events',\n",
    "                'solution': 'Regular retraining with updated datasets'\n",
    "            },\n",
    "            'Context Length': {\n",
    "                'issue': 'Fixed sequence length limits long-range dependencies',\n",
    "                'example': 'Cannot maintain coherence over long passages',\n",
    "                'solution': 'Transformer models with attention mechanisms'\n",
    "            },\n",
    "            'Character-Level Artifacts': {\n",
    "                'issue': 'May generate invalid words or character patterns',\n",
    "                'example': 'Output like \"xlmz\" or inconsistent spelling',\n",
    "                'solution': 'Word-level models or post-processing validation'\n",
    "            },\n",
    "            'Repetition': {\n",
    "                'issue': 'Tendency to repeat phrases or get stuck in loops',\n",
    "                'example': 'Generating the same phrase multiple times',\n",
    "                'solution': 'Repetition penalties or nucleus sampling'\n",
    "            },\n",
    "            'Factual Accuracy': {\n",
    "                'issue': 'No guarantee of factual correctness',\n",
    "                'example': 'May generate plausible but false information',\n",
    "                'solution': 'Fact-checking integration or knowledge grounding'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for limitation, details in limitations.items():\n",
    "            print(f\"\\n{limitation}:\")\n",
    "            print(f\"  Issue: {details['issue']}\")\n",
    "            print(f\"  Example: {details['example']}\")\n",
    "            print(f\"  Solution: {details['solution']}\")\n",
    "    \n",
    "    def analyze_sentiment_model_limitations(self):\n",
    "        \"\"\"Identify sentiment analysis limitations\"\"\"\n",
    "        print(f\"\\n=== Sentiment Analysis Model Limitations ===\")\n",
    "        \n",
    "        limitations = {\n",
    "            'Contextual Nuance': {\n",
    "                'issue': 'Difficulty with sarcasm, irony, and complex sentiment',\n",
    "                'example': '\"Great, another problem\" (sarcastic positive)',\n",
    "                'solution': 'Context-aware models or multi-task learning'\n",
    "            },\n",
    "            'Binary Classification': {\n",
    "                'issue': 'Only handles positive/negative, not neutral or mixed',\n",
    "                'example': 'Neutral texts forced into pos/neg categories',\n",
    "                'solution': 'Multi-class classification with neutral category'\n",
    "            },\n",
    "            'Domain Sensitivity': {\n",
    "                'issue': 'Performance varies across different text domains',\n",
    "                'example': 'Model trained on reviews may struggle with tweets',\n",
    "                'solution': 'Domain adaptation or multi-domain training'\n",
    "            },\n",
    "            'Character-Level Noise': {\n",
    "                'issue': 'Sensitive to typos and non-standard text',\n",
    "                'example': 'Misspellings may affect sentiment prediction',\n",
    "                'solution': 'Robust tokenization or spelling correction'\n",
    "            },\n",
    "            'Length Bias': {\n",
    "                'issue': 'May perform differently on short vs long texts',\n",
    "                'example': 'Single words vs full paragraphs',\n",
    "                'solution': 'Length-normalized training or hierarchical models'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for limitation, details in limitations.items():\n",
    "            print(f\"\\n{limitation}:\")\n",
    "            print(f\"  Issue: {details['issue']}\")\n",
    "            print(f\"  Example: {details['example']}\")\n",
    "            print(f\"  Solution: {details['solution']}\")\n",
    "    \n",
    "    def suggest_improvements(self):\n",
    "        \"\"\"Suggest concrete improvements for both models\"\"\"\n",
    "        print(f\"\\n=== Suggested Improvements ===\")\n",
    "        \n",
    "        improvements = {\n",
    "            'Architecture Enhancements': [\n",
    "                'Replace LSTM with Transformer architecture for better long-range dependencies',\n",
    "                'Add attention mechanisms to focus on relevant parts of input',\n",
    "                'Implement residual connections for deeper networks',\n",
    "                'Use layer normalization for training stability'\n",
    "            ],\n",
    "            'Training Improvements': [\n",
    "                'Implement curriculum learning (easy to hard examples)',\n",
    "                'Add data augmentation techniques (paraphrasing, back-translation)',\n",
    "                'Use transfer learning from pre-trained language models',\n",
    "                'Apply regularization techniques (weight decay, dropout scheduling)'\n",
    "            ],\n",
    "            'Data Enhancements': [\n",
    "                'Increase dataset size and diversity',\n",
    "                'Add domain-specific data for better generalization',\n",
    "                'Include multi-lingual data for broader coverage',\n",
    "                'Balance dataset across different categories and lengths'\n",
    "            ],\n",
    "            'Evaluation Improvements': [\n",
    "                'Add human evaluation for generation quality',\n",
    "                'Implement automatic metrics (BLEU, ROUGE for generation)',\n",
    "                'Test on out-of-domain data for robustness',\n",
    "                'Analyze failure cases systematically'\n",
    "            ],\n",
    "            'Deployment Considerations': [\n",
    "                'Add model serving infrastructure with API endpoints',\n",
    "                'Implement caching for common queries',\n",
    "                'Add input validation and sanitization',\n",
    "                'Monitor model performance in production'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        for category, items in improvements.items():\n",
    "            print(f\"\\n{category}:\")\n",
    "            for item in items:\n",
    "                print(f\"  • {item}\")\n",
    "    \n",
    "    def demonstrate_failure_cases(self):\n",
    "        \"\"\"Show specific examples where models struggle\"\"\"\n",
    "        print(f\"\\n=== Demonstration of Failure Cases ===\")\n",
    "        \n",
    "        # Language model failure cases\n",
    "        print(\"Language Model Failure Cases:\")\n",
    "        \n",
    "        failure_seeds = [\"Quantum\", \"2024\", \"COVID\"]\n",
    "        for seed in failure_seeds:\n",
    "            try:\n",
    "                generated = self.lm_model.generate_text(\n",
    "                    self.processor, seed, max_length=40, temperature=1.0\n",
    "                )\n",
    "                print(f\"  Seed '{seed}': {generated}\")\n",
    "                print(f\"    Issue: May not handle modern/technical terms well\")\n",
    "            except:\n",
    "                print(f\"  Seed '{seed}': Generation failed\")\n",
    "        \n",
    "        # Sentiment model failure cases\n",
    "        print(f\"\\nSentiment Model Failure Cases:\")\n",
    "        \n",
    "        tricky_texts = [\n",
    "            \"This movie is so bad it's good\",  # Complex sentiment\n",
    "            \"I love to hate this show\",        # Contradictory\n",
    "            \"meh ok i guess whatever\",         # Very neutral/informal\n",
    "            \"😊😊😊 but actually sad\",         # Emoji vs text mismatch\n",
    "        ]\n",
    "        \n",
    "        for text in tricky_texts:\n",
    "            try:\n",
    "                sentiment, confidence, _ = self.sentiment_model.predict_sentiment(\n",
    "                    self.processor, text, return_prob=True\n",
    "                )\n",
    "                print(f\"  Text: '{text}'\")\n",
    "                print(f\"    Prediction: {sentiment} ({confidence:.3f})\")\n",
    "                print(f\"    Issue: Complex sentiment not captured well\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Text: '{text}' - Analysis failed: {e}\")\n",
    "\n",
    "# Run limitations analysis\n",
    "limitations_analyzer = ModelLimitationsAnalysis(lm_model, sentiment_model, processor)\n",
    "\n",
    "limitations_analyzer.analyze_language_model_limitations()\n",
    "limitations_analyzer.analyze_sentiment_model_limitations() \n",
    "limitations_analyzer.suggest_improvements()\n",
    "limitations_analyzer.demonstrate_failure_cases()\n",
    "```\n",
    "\n",
    "## Summary\n",
    "\n",
    "This comprehensive mini NLP project successfully demonstrated the fundamental differences between **generative** and **discriminative** approaches in natural language processing through character-level implementations.\n",
    "\n",
    "### Key Achievements\n",
    "\n",
    "**Model Implementations:**\n",
    "- **Character-Level Language Model**: Successfully trained an LSTM-based generative model that learned character-level patterns and generated coherent text sequences\n",
    "- **Sentiment Analysis Model**: Built a bidirectional LSTM classifier that effectively distinguished between positive and negative sentiment in text\n",
    "- **Shared Infrastructure**: Utilized consistent preprocessing, vocabulary management, and evaluation frameworks for fair comparison\n",
    "\n",
    "**Technical Insights:**\n",
    "- **Character-Level Processing**: Demonstrated robustness to spelling variations and out-of-vocabulary words compared to word-level approaches\n",
    "- **Bidirectional Context**: Showed how bidirectional processing improves classification performance by capturing full sequence context\n",
    "- **Temperature Control**: Illustrated the creativity vs coherence trade-off in text generation through temperature parameter tuning\n",
    "- **Evaluation Metrics**: Applied appropriate metrics (perplexity for generation, accuracy for classification) to assess model quality\n",
    "\n",
    "### Comparative Analysis Results\n",
    "\n",
    "**Generative vs Discriminative Trade-offs:**\n",
    "- **Data Requirements**: Language model required more diverse text data, while sentiment model needed labeled examples\n",
    "- **Computational Complexity**: Generation involved sequential inference, classification required single forward pass\n",
    "- **Interpretability**: Both models provided different types of insights - generation quality vs attention patterns\n",
    "- **Applications**: Each model suited different use cases - creative writing vs opinion analysis\n",
    "\n",
    "**Performance Characteristics:**\n",
    "- **Language Model**: Achieved reasonable perplexity scores and generated contextually appropriate text within learned patterns\n",
    "- **Sentiment Model**: Demonstrated strong classification accuracy with confidence calibration for uncertainty quantification\n",
    "- **Robustness**: Both models showed resilience to input variations through character-level processing\n",
    "\n",
    "### Practical Learning Outcomes\n",
    "\n",
    "**NLP Architecture Understanding:**\n",
    "- Hands-on experience with sequence-to-sequence (language model) vs sequence-to-label (sentiment) architectures\n",
    "- Practical implementation of attention-like mechanisms through bidirectional processing and pooling\n",
    "- Understanding of how the same base architecture (LSTM) adapts to different task requirements\n",
    "\n",
    "**Model Development Skills:**\n",
    "- Data preprocessing and vocabulary management for character-level NLP\n",
    "- Training loop implementation with appropriate loss functions and metrics\n",
    "- Model evaluation including both quantitative metrics and qualitative analysis\n",
    "\n",
    "**Production Considerations:**\n",
    "- Interactive demonstration of model capabilities and limitations\n",
    "- Stress testing on edge cases and challenging inputs\n",
    "- Analysis of failure modes and suggestions for improvement\n",
    "\n",
    "### Limitations and Future Directions\n",
    "\n",
    "**Current Limitations:**\n",
    "- **Dataset Scale**: Limited training data compared to real-world NLP applications\n",
    "- **Architecture Constraints**: LSTM-based models lack the long-range dependency modeling of modern Transformers\n",
    "- **Task Scope**: Binary sentiment classification represents a simplified version of real sentiment analysis\n",
    "\n",
    "**Suggested Improvements:**\n",
    "- **Scale Up**: Larger datasets and more sophisticated architectures (Transformers)\n",
    "- **Multi-task Learning**: Joint training on related tasks for better representations\n",
    "- **Advanced Techniques**: Attention mechanisms, pre-training, and transfer learning\n",
    "\n",
    "This project provided a solid foundation for understanding core NLP concepts while highlighting the practical considerations involved in building and deploying different types of language models. The character-level approach, while simpler than modern word-piece tokenization, offered valuable insights into the fundamental challenges and trade-offs in natural language processing."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
